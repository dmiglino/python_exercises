{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3db66d71-a850-401a-9e18-d9f1768f92f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def descenso_de_gradiente(grad_f, x0, ratio, tolerancia, maxiter):\n",
    "    \"\"\"\n",
    "    Método de descenso de gradiente para minimizar funciones de una variable.\n",
    "\n",
    "    Args:\n",
    "        grad_f (function): Función que calcula la derivada de g, con entrada un escalar x.\n",
    "        x0 (list): Lista inicial (punto de partida en R^1).\n",
    "        ratio (float): Tasa de aprendizaje.\n",
    "        tolerancia (float): Tolerancia para la norma del gradiente.\n",
    "        maxiter (int): Número máximo de iteraciones.\n",
    "\n",
    "    Returns:\n",
    "        float: Aproximación del punto x donde g'(x) ≈ 0.\n",
    "    \"\"\"\n",
    "    x = np.array(x0, dtype=float)  # Convertir x0 a un arreglo de tipo flotante\n",
    "    for i in range(maxiter):\n",
    "        grad = grad_f(x)  # Calcular el gradiente en el punto actual\n",
    "\n",
    "        if np.linalg.norm(grad, ord=2) < tolerancia:  # Criterio de parada\n",
    "            print(f\"Convergencia alcanzada en la iteración {i+1}\")\n",
    "            return x\n",
    "\n",
    "        # Detectar overflow o valores no numéricos\n",
    "        if np.any(np.isnan(grad)) or np.any(np.isinf(grad)):\n",
    "            print(f\"Error numérico en la iteración {i+1}: gradiente no definido.\")\n",
    "            return None\n",
    "\n",
    "        x = x - ratio * grad  # Actualizar x usando la regla de descenso de gradiente\n",
    "\n",
    "    print(\"Número máximo de iteraciones alcanzado.\")\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd2bc052-8719-4641-9f21-fae2cb1a8dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergencia alcanzada en la iteración 880\n",
      "Punto encontrado: [-1.49999999 -1.49999995]\n"
     ]
    }
   ],
   "source": [
    "def grad_f(x):\n",
    "    return 2 * x + 3  # Gradiente de f(x) = x^2 + x^3 es ∇f(x) = [2*x2, 3*x]\n",
    "\n",
    "x0 = [-1.0, 1.0]  # Punto inicial\n",
    "ratio = 0.01  # Tasa de aprendizaje\n",
    "tolerancia = 0.0000001  # Tolerancia\n",
    "maxiter = 10000  # Número máximo de iteraciones\n",
    "\n",
    "result = descenso_de_gradiente(grad_f, x0, ratio, tolerancia, maxiter)\n",
    "print(\"Punto encontrado:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6c95093-af51-47cd-a6b0-3a281ba5a932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergencia alcanzada en la iteración 1595\n",
      "2c-I - Punto encontrado: [-2.24999895  1.49999961]\n",
      "Convergencia alcanzada en la iteración 1\n",
      "2c-II - Punto encontrado: [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def grad_f(x):\n",
    "    \"\"\"\n",
    "    Gradiente de la función g(x, y) = x^2 + y^3 + 3xy + 1.\n",
    "    \n",
    "    Args:\n",
    "        x (np.ndarray): Vector [x, y].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Gradiente [∂g/∂x, ∂g/∂y].\n",
    "    \"\"\"\n",
    "    grad_x = 2 * x[0] + 3 * x[1]  # ∂g/∂x\n",
    "    grad_y = 3 * x[1]**2 + 3 * x[0]  # ∂g/∂y\n",
    "    return np.array([grad_x, grad_y])\n",
    "\n",
    "x0 = [-1.0, 1.0]  # Punto inicial\n",
    "ratio = 0.01  # Tasa de aprendizaje\n",
    "tolerancia = 0.000001  # Tolerancia\n",
    "maxiter = 10000  # Número máximo de iteraciones\n",
    "\n",
    "result = descenso_de_gradiente(grad_f, x0, ratio, tolerancia, maxiter)\n",
    "print(\"2c-I - Punto encontrado:\", result)\n",
    "\n",
    "x0 = [0.0, 0.0]  # Punto inicial\n",
    "result = descenso_de_gradiente(grad_f, x0, ratio, tolerancia, maxiter)\n",
    "print(\"2c-II - Punto encontrado:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c8017a0-4ed9-4abb-bf55-65f953747ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número máximo de iteraciones alcanzado.\n",
      "2b-I - Punto encontrado: [1.]\n",
      "Convergencia alcanzada en la iteración 32\n",
      "2b-II - Punto encontrado: [-2.]\n",
      "Error numérico en la iteración 6: gradiente no definido.\n",
      "2b-IV - Punto encontrado: None\n",
      "Convergencia alcanzada en la iteración 1\n",
      "2b-V - Punto encontrado: [0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_136648/3720446345.py:3: RuntimeWarning: overflow encountered in power\n",
      "  return 12 * x**3 + 12 * x**2 - 24 * x\n"
     ]
    }
   ],
   "source": [
    "# Derivada de g(x)\n",
    "def grad_f(x):\n",
    "    return 12 * x**3 + 12 * x**2 - 24 * x\n",
    "\n",
    "x0 = [3]  # Punto inicial\n",
    "ratio = 0.0001  # Tasa de aprendizaje\n",
    "tolerancia = 1e-12  # Tolerancia\n",
    "maxiter = 10000  # Número máximo de iteraciones\n",
    "\n",
    "# Caso 1\n",
    "result = descenso_de_gradiente(grad_f, x0, ratio, tolerancia, maxiter)\n",
    "print(\"2b-I - Punto encontrado:\", result)\n",
    "\n",
    "# Caso 2\n",
    "ratio = 0.01\n",
    "result = descenso_de_gradiente(grad_f, x0, ratio, tolerancia, maxiter)\n",
    "print(\"2b-II - Punto encontrado:\", result)\n",
    "\n",
    "# Caso 3\n",
    "ratio = 0.1\n",
    "result = descenso_de_gradiente(grad_f, x0, ratio, tolerancia, maxiter)\n",
    "print(\"2b-IV - Punto encontrado:\", result)\n",
    "\n",
    "# Caso 4\n",
    "x0 = [0]\n",
    "ratio = 0.001\n",
    "result = descenso_de_gradiente(grad_f, x0, ratio, tolerancia, maxiter)\n",
    "print(\"2b-V - Punto encontrado:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8078aba0-59c3-4af3-bd40-18af2508291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4999999999999947 1.0658141036401503e-14 10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ratio = 0.01\n",
    "tolerancia = 0.0000001\n",
    "maxiter = 10000\n",
    "i = 0\n",
    "x = -1\n",
    "grad_fx = 2*x + 3\n",
    "xs = grad_fx\n",
    "x = x-xs*ratio\n",
    "\n",
    "while(i < maxiter):\n",
    "    i += 1\n",
    "    grad_fx = 2*x + 3\n",
    "    xs = grad_fx\n",
    "    x = x-xs*ratio\n",
    "    if (i == maxiter):\n",
    "        print(x, abs(xs), i)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc05c1-33e2-49f8-a33f-38e9983be0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b158153-f3d9-40c3-a279-6215de3452ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
